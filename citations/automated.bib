% Automated Prompt Engineering
% definition of prompting
@article{shin2020autoprompt,
   title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
   url={http://dx.doi.org/10.18653/v1/2020.emnlp-main.346},
   DOI={10.18653/v1/2020.emnlp-main.346},
   journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher={Association for Computational Linguistics},
   author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L. and Wallace, Eric and Singh, Sameer},
   year={2020} }

% 
@misc{zhou2022large,
    lp_title={automatic prompt engineer},
    title={Large Language Models Are Human-Level Prompt Engineers},
    author={Yongchao Zhou and Andrei Ioan Muresanu and Ziwen Han and Keiran Paster and Silviu Pitis and Harris Chan and Jimmy Ba},
    year={2022},
    eprint={2211.01910},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@misc{lester2021power,
    lp_title={Soft Prompting},
    title={The Power of Scale for Parameter-Efficient Prompt Tuning},
    author={Brian Lester and Rami Al-Rfou and Noah Constant},
    year={2021},
    eprint={2104.08691},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{khashabi2021prompt,
    lp_title={discretized soft prompting (interpreting)},
    title={Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts},
    author={Daniel Khashabi and Shane Lyu and Sewon Min and Lianhui Qin and Kyle Richardson and Sean Welleck and Hannaneh Hajishirzi and Tushar Khot and Ashish Sabharwal and Sameer Singh and Yejin Choi},
    year={2021},
    eprint={2112.08348},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}